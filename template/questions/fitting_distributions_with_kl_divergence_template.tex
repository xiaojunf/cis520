\section{Fitting distributions with KL divergence}

\begin{enumerate}
\item KL divergence for Gaussians.
  \begin{enumerate}
  \item The KL divergence between two univariate Gaussians is given by
    $f = \ldots$ and $g = \ldots$.
    \begin{align*}
      KL(p(x) || q(x)) =&\; \ldots \\
      =&\; \ldots \\
      =&\; \mathbf{E}_p[ f(x, \mu_1, \mu_2, \sigma)] + g(\sigma)
    \end{align*}
  \item The value $\mu_1 = \ldots$ minimizes $KL(p(x)||q(x))$.
    \begin{align*}
      0 =&\; \frac{\partial KL(p(x) || q(x))}{\partial \mu_1} \\
      0 =&\; \ldots \\
      \mu_1 =&\; \ldots
    \end{align*}
  \end{enumerate}

\item KL divergence for Multinomials.
  \begin{enumerate}
  \item The KL divergence between two Multinomials is: $KL(p(x) || q(x)) = \ldots$.

  \item The values $\alpha = \ldots$ and $\beta = \ldots$ minimize $KL(p(x)||q(x))$.
    \begin{align*}
      \textrm{Lagrangian}\;\; \mathcal{L} =&\; \ldots \\
      =&\; \ldots
    \end{align*}
  \end{enumerate}
\end{enumerate}
